<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data | Kevin Pratama</title>
<meta name="keywords" content="cvpr">
<meta name="description" content="This paper reviews unusual uses for olive oil throughout the Mediterranean world. Published in the Journal of Oleic Science, 2013.">
<meta name="author" content="Shichao Li,&thinsp;Lei Ke,&thinsp;Kevin Pratama,&thinsp;Yu-Wing Tai,&thinsp;Chi-Keung Tang,&thinsp;Kwang-Ting Cheng">
<link rel="canonical" href="https://pascalmichaillat.org/hugo-website/papers/paper1/">
<link crossorigin="anonymous" href="/hugo-website/assets/css/stylesheet.814495f0afdcdaa33dbf31beb2089c74538c6c2e3b5b9182ae4ae787aec0b7c4.css" integrity="sha256-gUSV8K/c2qM9vzG&#43;sgicdFOMbC47W5GCrkrnh67At8Q=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://pascalmichaillat.org/hugo-website/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://pascalmichaillat.org/hugo-website/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://pascalmichaillat.org/hugo-website/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://pascalmichaillat.org/hugo-website/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://pascalmichaillat.org/hugo-website/papers/paper1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data" />
<meta property="og:description" content="This paper reviews unusual uses for olive oil throughout the Mediterranean world. Published in the Journal of Oleic Science, 2013." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://pascalmichaillat.org/hugo-website/papers/paper1/" />
<meta property="og:image" content="https://pascalmichaillat.org/hugo-website/paper1.png" /><meta property="article:section" content="papers" />
<meta property="article:published_time" content="2020-06-14T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-07-12T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://pascalmichaillat.org/hugo-website/paper1.png" />
<meta name="twitter:title" content="Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data"/>
<meta name="twitter:description" content="This paper reviews unusual uses for olive oil throughout the Mediterranean world. Published in the Journal of Oleic Science, 2013."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Papers",
      "item": "https://pascalmichaillat.org/hugo-website/papers/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data",
      "item": "https://pascalmichaillat.org/hugo-website/papers/paper1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data",
  "name": "Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data",
  "description": "This paper reviews unusual uses for olive oil throughout the Mediterranean world. Published in the Journal of Oleic Science, 2013.",
  "keywords": [
    "cvpr"
  ],
  "articleBody": " Download Paper Code and data Abstract End-to-end deep representation learning has achieved remarkable accuracy for monocular 3D human pose estimation, yet these models may fail for unseen poses with limited and fixed training data. This paper proposes a novel data augmentation method that: (1) is scalable for synthesizing massive amount of training data (over 8 million valid 3D human poses with corresponding 2D projections) for training 2D-to-3D networks, (2) can effectively reduce dataset bias. Our method evolves a limited dataset to synthesize unseen 3D human skeletons based on a hierarchical human representation and heuristics inspired by prior knowledge. Extensive experiments show that our approach not only achieves state-of-the-art accuracy on the largest public benchmark, but also generalizes significantly better to unseen and rare poses. Code, pre-trained models and tools are available at this HTTPS URL.\nCitation Li, Shichao, et al. “Cascaded deep monocular 3d human pose estimation with evolutionary training data.” Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n@inproceedings{Li_2020, title={Cascaded Deep Monocular 3D Human Pose Estimation With Evolutionary Training Data}, url={http://dx.doi.org/10.1109/CVPR42600.2020.00621}, DOI={10.1109/cvpr42600.2020.00621}, booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, publisher={IEEE}, author={Li, Shichao and Ke, Lei and Pratama, Kevin and Tai, Yu-Wing and Tang, Chi-Keung and Cheng, Kwang-Ting}, year={2020}, month=jun, pages={6172–6182} } ",
  "wordCount" : "209",
  "inLanguage": "en",
  "image":"https://pascalmichaillat.org/hugo-website/paper1.png","datePublished": "2020-06-14T00:00:00Z",
  "dateModified": "2024-07-12T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Shichao Li"
  }, {
    "@type": "Person",
    "name": "Lei Ke"
  }, {
    "@type": "Person",
    "name": "Kevin Pratama"
  }, {
    "@type": "Person",
    "name": "Yu-Wing Tai"
  }, {
    "@type": "Person",
    "name": "Chi-Keung Tang"
  }, {
    "@type": "Person",
    "name": "Kwang-Ting Cheng"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://pascalmichaillat.org/hugo-website/papers/paper1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Kevin Pratama",
    "logo": {
      "@type": "ImageObject",
      "url": "https://pascalmichaillat.org/hugo-website/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://pascalmichaillat.org/hugo-website/" accesskey="h" title="Kevin Pratama">
                <img src="https://pascalmichaillat.org/hugo-website/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Kevin Pratama</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://pascalmichaillat.org/hugo-website/papers/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="https://kpkepra.substack.com/" title="Blog">
                    <span>Blog</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Cascaded Deep Monocular 3D Human Pose Estimation with Evolutionary Training Data
    </h1>
    <div class="post-meta"><span title='2020-06-14 00:00:00 +0000 UTC'>June 2020</span>&nbsp;&middot;&nbsp;Shichao Li,&thinsp;Lei Ke,&thinsp;Kevin Pratama,&thinsp;Yu-Wing Tai,&thinsp;Chi-Keung Tang,&thinsp;Kwang-Ting Cheng&nbsp;&middot;&nbsp;<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Cascaded_Deep_Monocular_3D_Human_Pose_Estimation_With_Evolutionary_Training_CVPR_2020_paper.html" rel="noopener noreferrer" target="_blank">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 6173-6183</a>

</div>
  </header> 
  <div class="post-content"><hr>
<h5 id="download">Download</h5>
<ul>
<li><a href="paper1.pdf">Paper</a></li>
</ul>
<!-- + [Online appendix](appendix1.pdf) -->
<ul>
<li><a href="https://github.com/Nicholasli1995/EvoSkeleton" target="_blank">Code and data</a></li>
</ul>
<hr>
<h5 id="abstract">Abstract</h5>
<p>End-to-end deep representation learning has achieved remarkable accuracy for monocular 3D human pose estimation, yet these models may fail for unseen poses with limited and fixed training data. This paper proposes a novel data augmentation method that: (1) is scalable for synthesizing massive amount of training data (over 8 million valid 3D human poses with corresponding 2D projections) for training 2D-to-3D networks, (2) can effectively reduce dataset bias. Our method evolves a limited dataset to synthesize unseen 3D human skeletons based on a hierarchical human representation and heuristics inspired by prior knowledge. Extensive experiments show that our approach not only achieves state-of-the-art accuracy on the largest public benchmark, but also generalizes significantly better to unseen and rare poses. Code, pre-trained models and tools are available at this HTTPS URL.</p>
<hr>
<p><img loading="lazy" src="paper1.png" alt=""  />
</p>
<hr>
<h5 id="citation">Citation</h5>
<p>Li, Shichao, et al. &ldquo;Cascaded deep monocular 3d human pose estimation with evolutionary training data.&rdquo; Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-BibTeX" data-lang="BibTeX"><span style="display:flex;"><span><span style="color:#0a0;text-decoration:underline">@inproceedings</span>{Li_2020,
</span></span><span style="display:flex;"><span>   <span style="color:#1e90ff">title</span>=<span style="color:#a50">{Cascaded Deep Monocular 3D Human Pose Estimation With Evolutionary Training Data}</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#1e90ff">url</span>=<span style="color:#a50">{http://dx.doi.org/10.1109/CVPR42600.2020.00621}</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#1e90ff">DOI</span>=<span style="color:#a50">{10.1109/cvpr42600.2020.00621}</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#1e90ff">booktitle</span>=<span style="color:#a50">{2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#1e90ff">publisher</span>=<span style="color:#a50">{IEEE}</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#1e90ff">author</span>=<span style="color:#a50">{Li, Shichao and Ke, Lei and Pratama, Kevin and Tai, Yu-Wing and Tang, Chi-Keung and Cheng, Kwang-Ting}</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#1e90ff">year</span>=<span style="color:#a50">{2020}</span>,
</span></span><span style="display:flex;"><span>   <span style="color:#1e90ff">month</span>=<span style="color:#a00">jun</span>, <span style="color:#1e90ff">pages</span>=<span style="color:#a50">{6172–6182}</span> }
</span></span></code></pre></div><hr>
<!-- ##### Related material

+ [Presentation slides](presentation1.pdf)
+ [Summary of the paper](https://www.penguinrandomhouse.com/books/110403/unusual-uses-for-olive-oil-by-alexander-mccall-smith/) -->

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://pascalmichaillat.org/hugo-website/tags/cvpr/">Cvpr</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://pascalmichaillat.org/hugo-website/">Kevin Pratama</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
